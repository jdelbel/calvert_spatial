---
title: "R Notebook"
output: html_notebook
---

```{r}
#Load packages
library(tidyverse)
library(patchwork)
library(here)
library(readr)
library(readxl)
```

```{r}
#Upload fully formatted microscopy data
# micro <- read_csv(here("outputs", "micro_master_2021-10-18.csv"))

#Upload microscopy data merged with physical and biogeochemical measures
data <- read_csv(here("outputs", "ctd_merge_2021-11-04_chem.csv")) 

#Uploading chemtax data
# chem <- read_csv(here("outputs", "chemtax_master_2021-11-04.csv"))

#Uploading PCA Clustering data
# pca_clust <- read_csv(here("outputs", "clusters_phys_2022-04-19.csv"))

#Uploading corrected chlorophyll data
# chla <- read_csv(here("outputs", "bulk_chla_corrected.csv"))

```

```{r}
#Removing QU39 from sheets
# micro <- micro %>% 
#   filter(!site_id == "QU39")

data <- data %>% 
  filter(!site_id == "QU39")
```

```{r}
#Adding location to sheets and then creating unique station names for merging and plotting

#Making a location column.
data <- data %>% 
    mutate(location = case_when(site_id == "DFO2" ~ "F",
                              site_id == "KC10" ~ "C",
                              site_id == "QCS01" ~ "S",
                              TRUE ~ as.character(site_id)))

# micro <- micro %>% 
#     mutate(location = case_when(site_id == "DFO2" ~ "F",
#                               site_id == "KC10" ~ "C",
#                               site_id == "QCS01" ~ "S",
#                               TRUE ~ as.character(site_id)))

#Order locations from fjord to shelf
order_loc <- c("F", "C", "S")

#Apply ordering to data for 
data <- arrange(mutate(data,
                       location = factor(location, levels = order_loc)))

# micro <- arrange(mutate(micro,
#                        location = factor(location, levels = order_loc)))
```

```{r}
pys_chem <- data %>% 
  select(location, temp_dm:secchi_depth)
```




```{r}
#Creating site-id for merging with PCA clusters.
# data <- data %>% 
#   unite(sample_name, c(location, date), sep = "", remove = FALSE) %>% 
#   relocate(sample_name, .before = date)

#Merging with PCA clusters
# data <- data %>% 
#   left_join(pca_clust)
```

```{r}
#I want to look at annual averages of important variables

#Global medians grouped by station
data_glob_loc <- data %>% 
  filter(!site_id == "QU39") %>% 
  select(location, temp_dm:bulk_chl) %>% 
  mutate(n_p = no2_dm/po4_dm,
         si_n = sio2_dm/no2_dm) %>% 
  group_by(location) %>% 
  summarise(across(temp_dm:si_n, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()

#Global medians grouped by PCA cluster
data_glob_clust <- data %>% 
  filter(!site_id == "QU39" & !is.na(cluster)) %>% 
  select(cluster, temp_dm:bulk_chl) %>% 
  mutate(n_p = no2_dm/po4_dm,
         si_n = sio2_dm/no2_dm) %>% 
  group_by(cluster) %>% 
  summarise(across(temp_dm:si_n, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()

```


```{r}
#Statistical tests showed that silicate was different between years for DFO2 only

#Looking at annual means in silicate for DFO2
annual_dfo2_sio2 <- data %>% 
  mutate(year = lubridate::year(date)) %>% 
  filter(site_id == "DFO2") %>% 
  select(year, sio2_dm) %>% 
  group_by(year) %>% 
  summarise(across(sio2_dm, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()
```


```{r}
#Nutrient Ratios show some crazy trends due to zero values. Filtering out for stats calculationg.

#Removing zero PO4 values
n_p <- data %>% 
  filter(!site_id == "QU39") %>%
  mutate(year = lubridate::year(date)) %>% 
  select(year, location, cluster, no2_dm, po4_dm) %>% 
  filter(po4_dm > 0.5) %>% 
  mutate(n_p = no2_dm/po4_dm)
  
#Calculating stats for N:P by station
n_p_loc <- n_p %>% 
  group_by(location) %>% 
  summarise(across(n_p, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()

#Calculating stats for N:P by cluster
n_p_clust <- n_p %>% 
  group_by(cluster) %>% 
  summarise(across(n_p, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()

#Doing the same as above for the Si:N ratio
data_test <- data %>% 
  filter(!site_id == "QU39") %>% 
  mutate(year = lubridate::year(date)) %>%
  select(year, location, cluster, sio2_dm, no2_dm) %>% 
  filter(no2_dm > 0 & sio2_dm > 0) %>% 
  mutate(s_n = sio2_dm/no2_dm)


s_n <- data %>% 
  filter(!site_id == "QU39") %>% 
  mutate(year = lubridate::year(date)) %>%
  select(year, location, cluster, sio2_dm, no2_dm) %>% 
  filter(no2_dm > 0 & sio2_dm > 0) %>% 
  mutate(s_n = sio2_dm/no2_dm) 


s_n_loc <- s_n %>% 
  group_by(location) %>% 
  summarise(across(s_n, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup() 

s_n_clust <- s_n %>% 
  group_by(cluster) %>% 
  summarise(across(s_n, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()
```

```{r}
#Trying Kruskal Wallis Test followed by Dunn's test if differences found. Instead of creating separate code for each parameter - just changing code depending on what I am looking at.


kruskal.test(s_n ~ location, data = data_test)

#Dunn
FSA::dunnTest(data_test$s_n ~ data_test$location,
         data = data,
         method = "bonferroni")

```
```{r}
#Trying Kruskal Wallis Test followed by Dunn's test if differences found. Instead of creating separate code for each parameter - just changing code depending on what I am looking at.

data_clust <- data %>% 
  filter(!is.na(cluster))

#Converting cluster to a factor to for Dunn's test
data_clust <- data_clust %>% 
  mutate(clust_factor = as.factor(cluster))

kruskal.test(no2_dm ~ cluster, data = data_clust)

#Dunn
FSA::dunnTest(no2_dm ~ clust_factor,
         data = data_clust,
         method = "bonferroni")

```





```{r}
#Also need to look at stats from TChla, which was calculated separately.


chl_stat <- chla %>% 
  group_by(location) %>% 
  summarise(across(chl, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()
```


```{r}
#Significant annual differences were observed between 2019 and 2020 at DFO2. Pulling these years out to look at values.
annual_dfo2_chl <- chl_merge %>% 
  mutate(year = lubridate::year(date)) %>% 
  filter(site_id == "DFO2") %>% 
  select(year, chl) %>% 
  group_by(year) %>% 
  summarise(across(chl, .f = list(mean = mean, median = median,
                                               min = min, max = max, sd = sd),
                   na.rm = TRUE)) %>% 
  ungroup()
```
