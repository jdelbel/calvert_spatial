---
title: "R Notebook"
output: html_notebook
---

 

```{r}
#Loading packages
library(tidyverse)
library(readxl)
library(gsw)
library(here)
library(vegan)
library(adespatial)
library(ggord)
```

```{r}
#Upload data

#ctd data with gsw calculations
ctd_calcs <- read_csv(here("outputs", "ctd_calcs.csv")) 

#delta rho data
ctd_dd <- read_csv(here("outputs", "ctd_dd.csv"))

#nutrient data
nuts <- read_csv(here("outputs", "nuts.csv"))

#turbidity data with offset corrections
turb_corr <- read_csv(here("outputs", "corrected_turbidity_v1.csv"))

```

```{r}
#Further work to some of the ctd data for merging

#Pulling out data I need for merging with ctd - There are duplicate casts here, so for now performing daily mean.
ctd_dd_dm <- ctd_dd %>% 
  select(date, station, delta_rho) %>% 
  mutate(ymd = lubridate::date(date)) %>% 
  group_by(ymd, station) %>% 
  summarise(dd_dm = mean(delta_rho)) %>%
  ungroup()
  

#Pulling out data I need for merging with ctd
turb_corr_dm <- turb_corr %>% 
  filter(pressure == 5) %>% 
  select(ymd = date, station, turb_cor) %>% 
  group_by(ymd, station) %>% 
  summarise(turb_dm = mean(turb_cor)) %>%
  ungroup()

#Finding the N2 max
n2_max_dm <- ctd_calcs %>% 
  mutate(ymd = lubridate::date(date)) %>%
  select(cast_pk, ymd, station, N2) %>% 
  group_by(cast_pk) %>% 
  mutate(n2_max = max(N2)) %>% 
  ungroup() %>% 
  distinct(cast_pk, n2_max, .keep_all = TRUE) %>% 
  group_by(ymd, station) %>% 
  summarise(n2_max_dm = mean(n2_max)) %>% 
  ungroup()
  
#cutting out data I am using from 5m depth - for some reason throwing tons of duplicates in temp/sal
ctd_dm <- ctd_calcs %>% 
  filter(pres == 5) %>%
  mutate(ymd = lubridate::date(date)) %>%
  select(ymd, station, temp, sal) %>%
  group_by(ymd, station) %>% 
  mutate(sal_dm = mean(sal),
         temp_dm = mean(temp)) %>% 
  ungroup() %>% 
  distinct(ymd, station, temp_dm, sal_dm)

nuts_dm <- nuts %>% 
  filter(line_out_depth == 5) %>% 
  select(ymd = date, station = site_id, no2_no3_um, sio2, po4) %>% 
  group_by(ymd, station) %>% 
  summarise(no2_dm = mean(no2_no3_um),
            sio2_dm = mean(sio2),
            po4_dm = mean(po4)) %>% 
  ungroup()
  
  
ctd_merge <- ctd_dm %>% 
  left_join(ctd_dd_dm, by = c("station", "ymd")) %>% 
  left_join(turb_corr_dm, by = c("station", "ymd")) %>% 
  left_join(n2_max_dm, by = c("station", "ymd")) %>% 
  left_join(nuts_dm, by = c("station", "ymd"))

#Cleaning/standardizing for merge with microscopy and chemtax
ctd <- ctd_merge %>% 
  rename(date = ymd, site_id = station, sal = sal_dm, temp = temp_dm,
         dr = dd_dm, turb = turb_dm, n2_max = n2_max_dm, no2 = no2_dm,
         sio2 = sio2_dm, po4 = po4_dm)

write_csv(ctd_merge, here("outputs", "ctd_merge.csv"))

#OK, so all of the physical and chemical data are merged. I could consider adding FWC, solar, wind, 1026 depth etc.
```
```{r}
#Upload Microscopy data
#Upload output from OBIS taxonomy matching/formatting for Calvert data.
cal <- read_csv(here("files", "calvert.csv")) 

qu39 <- read_csv(here("files", "qu39.csv"))

#Removing data outside of the date of investigation
# cal <- cal %>% 
#   filter(date > "2019-05-10" & date < "2019-12-01")

cal <- cal %>% 
  filter(trophicStatus == "auto")

#Selecting closest temporal stations from QU39
qu39 <- qu39 %>% 
  filter(trophicStatus == "auto")

qu39 <- qu39 %>% 
  filter(date == "2018-05-29" | #could also be 05-22
         date == "2018-06-26" |
         date == "2018-07-23" | # Could also be 07-16
         date == "2018-08-21" | # 08-14, 08-28
         date == "2018-09-13" |   
         date == "2018-10-24" |
         date == "2019-05-09" |
         date == "2019-06-04" |
         date == "2019-07-09" |
         date == "2019-08-07" |
         date == "2019-08-29" |
         date == "2019-10-09" |
         #date == "2019-11-26" | #removing this for multi-year analysis
         date == "2020-04-29" | #Different month, but very close temporally
         date == "2020-06-04" |
         date == "2020-07-09" | # Also 06-30 - Tricky
         date == "2020-08-04" | # Also 08-13 
         date == "2020-09-01" |
         date == "2020-10-08")
            
#Merge with qu39 and calvert
micro <- rbind(cal, qu39)

#Dates that were collected on the cusp of a month change - rest of survey was done in following month. Just done for ease of plotting.
micro <- micro%>%  
  mutate(month = lubridate::month(date),
         month = case_when(date == "2019-08-29" ~ 9,
                           date == "2019-08-31" ~ 9,
                           date == "2020-04-29" ~ 5,
                           date == "2020-04-30" ~ 5,
                             TRUE ~ as.numeric (month)))

micro <- micro %>% 
  filter(date > "2018-01-01" & date < "2021-01-01" & month > 4 & month < 11)

micro_distinct <- micro %>% 
  distinct(date, site_id)

# micro <- micro %>% 
#   filter(!site_id == "QU39")

```

```{r}
#Could try to limit cryptic species that influence stats. Leaving off for now.

#Only species occurring in 25% of the samples - could try this.

# Counting how many times each species is observed
micro <- micro %>%
   group_by(scientificName) %>%
   mutate(num_occurrence = n())

# removing species that have not been observed at least twice.
# micro <- micro %>%
#   filter(num_occurrence > 2)
```

```{r}
#Selecting columns
micro <- micro %>% 
  select(date, site_id, group, scientificName, count)

# Because I have some species separated out with identificationRemarks, identificationQualifiers and different resting stages, I sum these. If I don't, then the pivoting in later stages results in columns with combined numbers. I need to decide on best method for this once I have the analysis zeroed in. 

#I could re-merge the qualifiers with the name to separate out some of groups here, especially if they are important, such as the unidentified small dinoflagellates.

#Again, not sure if I want to do this...
# micro <- micro %>%
#   group_by(date, site_id, scientificName) %>%
#   summarize(species_sum = sum(count)) %>%
#   ungroup()

# micro_group <- micro %>% 
#   distinct(group)

micro <- micro %>%
  filter(!scientificName == "Protozoa") %>%
  group_by(date, site_id, scientificName) %>%
  summarize(species_sum = sum(count)) %>%
  ungroup()

# micro <- micro %>% 
#   filter(!scientificName == "Protozoa" & !site_id == "QU39") %>% 
#   group_by(date, site_id, group) %>% 
#   summarise(count  = sum(count)) %>% 
#   ungroup()

#pivoting longer so species are columns. 
micro_piv <- micro %>% 
  pivot_wider(names_from = scientificName, values_from = species_sum) %>% 
  mutate_if(is.numeric, ~ replace_na(., 0))

#Adding date columns
micro_piv <- micro_piv %>% 
  mutate(month = lubridate::month(date),
         yday = lubridate::yday(date)) %>% 
  relocate(month, .after = date) %>% 
  relocate(yday, .after = month)

#Roughly adding seasons - would like to make cosmological seasons
micro_piv <- micro_piv %>%
  mutate(season = case_when(month %in% c(12, 1, 2) ~ "winter",
                            month >= 3 & month <= 6 ~ "spring",
                            month >= 7 & month <= 9 ~ "summer",
                            month >= 10 & month <= 11 ~ "autumn",)) %>%
  relocate(season, .after = month)

micro_piv <- micro_piv %>% 
  arrange(site_id, date)

#Pulling out species counts for transform and input into clustering and NMDS
# transform <- micro_piv[, 6:ncol(micro_piv)]  
  
#Log10 transformation +1 (as per Mahara)
# transform <- log10(transform + 1)

#Performing clustering
# dend_micro <- transform %>% 
#   vegdist("bray") %>% 
#   hclust(method = "average") %>% 
#   as.dendrogram()


```





```{r}
#merging using the truncated microscopy data as

#Merging the microscopy data with the physical/chemical data. Here, the microscopy data was already filtered to the 2019 May to November period.
micro_merge <- micro_piv %>% 
  left_join(ctd, by = c("date", "site_id"))

```

```{r}
#Remove rows with NaNs
micro_merge <- micro_merge %>% 
  drop_na()

#Separating into response variables (CHEMTAX) and Explainatory variables (Environmental)
resp <- micro_merge[, 6:127]

#Things to add TChla, WSDP, iso depth, FWC...
expl <- micro_merge[, 128:ncol(micro_merge)]
```

```{r}
#Hellinger transformation on species data - particularly suited to species abundance data with large range and lots of zeros. Gives low weights to variables with low counts and many zeroes.
resp.hell <- decostand(resp,'hell')
```

```{r}
# dbRDA <- capscale(mont.spec.matrix.27 ~ , data=shannon.montast.env.site, distance = "bray")
```



```{r}
tbRDA.all <- rda(resp.hell ~ . , data = expl)

tbRDA.all

anova(tbRDA.all)

adjR2.tbrda <- RsquareAdj (tbRDA.all)$adj.r.squared

adjR2.tbrda

# Variables explain 13% of the variance
# RDA1 - 8.6%
# RDA2 - 2.7%
# PCA1 - 8.2%
# PCA2 - 2.0%

#Global model significant to 0.01 
```
```{r}
constrained_eig <- tbRDA.all$CCA$eig/tbRDA.all$tot.chi*100
unconstrained_eig <- tbRDA.all$CA$eig/tbRDA.all$tot.chi*100
expl_var <- c(constrained_eig, unconstrained_eig)
barplot (expl_var[1:20], col = c(rep ('red', length (constrained_eig)), rep ('black', length (unconstrained_eig))),
         las = 2, ylab = '% variation')
```

```{r}
ordiplot (tbRDA.all)
```


```{r}
#Using DCA on chemtax data to test whether linear or unimodal model is appropriate
DCA <- decorana(resp.hell)
DCA
#As the length of the first DCA is < 3 S.D. - the dataset is homogenous and a linear model is appropriate. The score went down after applying the Hellinger Transformation. Proceed with RDA.

```
```{r}
sel.fs <- forward.sel (Y = resp.hell, X = expl, adjR2thresh = adjR2.tbrda)
sel.fs
```

```{r}
#Forward selection RDA used to remove environmental variables that do not show significance. https://wiki.qcbs.ca/r_workshop10
# ?ordiR2step
ordiR2step(rda(resp.hell ~ 1, data = expl), scope = formula(tbRDA.all),
           direction = "forward", R2scope = TRUE, pstep = 1000)

#Only salinitity is significant to 0.004
```

```{r}
#Trying different approach for ordiR2step from https://www.davidzeleny.net/anadat-r/doku.php/en:forward_sel_examples - same result as my other test
tb_rda.vasc.0 <- rda (resp.hell ~ 1, data = expl)

tb_rda.vasc.all <- rda (resp.hell ~ ., data = expl)

sel.osR2 <- ordiR2step (tb_rda.vasc.0, scope = formula (tb_rda.vasc.all), 
                        R2scope = adjR2.tbrda, direction = 'forward', 
                        permutations = 999)

sel.osR2$anova

sel.osR2_adj <- sel.osR2

sel.osR2_adj$anova$`Pr(>F)` <- p.adjust (sel.osR2$anova$`Pr(>F)`, 
                                         method = 'holm', n = ncol (expl))

sel.osR2_adj$anova

#Again, only salinity is significant
```

```{r}
#Select the statistically significant variables - May want to remove SiO2, see VIFS below!
env.signif <- subset(expl, select = c(temp, po4, sal, no2))

#RDA using significant variables
rda.signif <- rda(resp.hell ~ . ,data = env.signif)
rda.signif
summary(rda.signif, display = NULL)

#Adjusted R2 for the 1 significant variables
#AdjR2 = 0.21
(R2adj <- RsquareAdj(rda.signif)$adj.r.squared)

#ANOVA for testing significance of model and individual axes #Can do ANOVA by terms...
#Entire model = 0.001***
#RDA1 = 0.001***
#RDA2 = 0.007**
#RDA3 = 0.028*
# ?anova.cca
anova.cca(rda.signif, step = 1000)
anova.cca(rda.signif, step = 1000, by = "axis")

#All significant - already shown in forward rda, but easier to see
anova(rda.signif, by = "terms")
```
```{r}

#Trying the same thing, but bringing in arrows from previous plot - trying scaling 2
#pdf(file = "rda_s2.pdf", width = 6.5, height = 5, pointsize = 2)

plot(rda.signif, scaling = 1, type = "none", xlab = c("RDA1 (28%)"),
               ylab = c("RDA2 (5%)"), xlim = c(-0.01, 0.1), ylim = c(-1.1, 1.1))

# points(rda.signif, display = 'sites', pch = 21, cex = 2.2,
#        col = rgb(red = 1, green = 1, blue = 1, alpha = 0.5), scaling = 2,
#        bg = bg[eco])

points(scores(rda.signif, display = 'sites', choices = c(1, 2), scaling = 1),
       pch = 21, cex = 2.0,
       bg = c("blue", "springgreen4", "black", "magenta")[as.factor(micro_merge$site_id)])

#So since distance doesn't matter, I can make arrows longer with scaling 2? 
# arrows(0,0, scores(rda.signif, display = "species", choices = c(1),
#                    scaling = 1), scores(rda.signif, display = "species",
#                                             choices = c(2), scaling = 1),
#        col = "black", length = 0)

text(rda.signif, scaling = 1, display = "bp", col = "blue",cex = 0.8, font = 2)

# text(scores(rda.signif, display = "species", choices = c(1), scaling = 1),
#      scores(rda.signif, display = "species", choices = c(2), scaling = 1),
#      labels = rownames(scores(rda.signif, display = "species", scaling = 1)),
#      col = "black", cex = 0.8, font = 2)


# legend("topleft", legend = levels(eco), bty ="n", col="gray32", pch = 21,
#        cex = 1.5, pt.bg = bg)

legend("topright", legend = c(levels(as.factor(micro_merge$site_id))),
       pch = 21,
       pt.bg = c("blue", "springgreen4", "black", "magenta"),
       bty = "n", cex = 1.5)

#dev.off()

```
```{r}
png(here("figures_new", "rda_micro.png"),
     width = 800, height = 500)

plot(rda.signif, scaling = 2, type = "none", xlab = c("RDA1 (28%)"),
               ylab = c("RDA2 (5%)"))

# , xlim = c(-0.01, 0.1), ylim = c(-1.1, 1.1)

# points(rda.signif, display = 'sites', pch = 21, cex = 2.2,
#        col = rgb(red = 1, green = 1, blue = 1, alpha = 0.5), scaling = 2,
#        bg = bg[eco])

points(scores(rda.signif, display = 'sites', choices = c(1, 2), scaling = 2),
       pch = 21, cex = 2.0,
       bg = c("blue", "springgreen4", "black", "magenta")[as.factor(micro_merge$site_id)])

#So since distance doesn't matter, I can make arrows longer with scaling 2? 
# arrows(0,0, scores(rda.signif, display = "species", choices = c(1),
#                    scaling = 1), scores(rda.signif, display = "species",
#                                             choices = c(2), scaling = 1),
#        col = "black", length = 0)

text(rda.signif, scaling = 2, display = "bp", col = "blue",cex = 0.8, font = 2)

# text(scores(rda.signif, display = "species", choices = c(1), scaling = 1),
#      scores(rda.signif, display = "species", choices = c(2), scaling = 1),
#      labels = rownames(scores(rda.signif, display = "species", scaling = 1)),
#      col = "black", cex = 0.8, font = 2)


# legend("topleft", legend = levels(eco), bty ="n", col="gray32", pch = 21,
#        cex = 1.5, pt.bg = bg)

legend("topright", legend = c(levels(as.factor(micro_merge$site_id))),
       pch = 21,
       pt.bg = c("blue", "springgreen4", "black", "magenta"),
       bty = "n", cex = 1.5)

dev.off()
```

```{r}
pl <- plot(rda.signif, scaling=2, main="Triplot RDA", type="none", xlab=c("RDA1"), ylab=c("RDA2"), 
     xlim=c(-0.5,0.5), ylim=c(-0.5,0.5))
splen <- sqrt(rowSums(pl$species^2))  # species distance from the origin in pl[ot]
points(pl, "sites", pch=21, col="black", cex=1.2)
text(pl, "species", select = splen > 0.5, arrow=TRUE, length=0.05) # harmless warning on length argument, but works
## Alternatively you can use magrittr pipes (if you have splen  or select vector calculated by other means):

```



```{r}
#Scaling 2
#When looking at scaling 2, variables approaching 90 degrees of each other have little correlation. Variables < 90 degrees have positive correlations and those > 90 degrees have negative correlations. Len Based on this the below plot suggests that 1) Diatoms are negatively correlated to temperature and stratification and also, all other phytoplankton groups. Cyanobacteria, Haptophytes and Dictyophytes are positively correlated to temperature and stratification, but show no relationship to NO2 and SiO2. Prasinophytes and Cryptophytes are positively correlated with SiO2 and NO2. This goes pretty strongly againts what the Spearman's rank analysis shows. What's more appropriate? Also, what would separating my data (by year, season) look like? https://wiki.qcbs.ca/r_workshop10

#eigenvectors for 
#explains a reasonable amount of 
plot(rda.signif, scaling = 2, main = "Triplot RDA - scaling 2", type = "none",
     xlab = c("RDA1 (31%)"), ylab = c("RDA2 (3%)"), xlim = c(-0.5, 0.5), 
     ylim = c(-1, 1))


points(scores(rda.signif, display = "sites", choices = c(1, 2), scaling = 2),
       pch = 21, col = "steelblue", bg = "steelblue", cex = 0.8)



# arrows(0, 0, scores(rda.signif, display = "species", choices = c(1), scaling = 2),
#        scores(rda.signif, display = "species", choices = c(2), scaling = 2),
#        col= "black", length=0)

# text(scores(rda.signif, display = "species", choices = c(1), scaling = 2),
#      scores(rda.signif, display = "species", choices = c(2), scaling = 2),
#      labels = rownames(scores(rda.signif, display = "species", scaling = 2)),
#      col = "black", cex = 0.8)    

arrows(0,0,
       scores(rda.signif, display = "bp", choices = c(1), scaling = 2),
       scores(rda.signif, display = "bp", choices = c(2), scaling = 2),
       col="red")

text(scores(rda.signif, display = "bp", choices = c(1), scaling = 2) + 0.05,
     scores(rda.signif, display = "bp", choices = c(2), scaling = 2)+ 0.05,
     labels = rownames(scores(rda.signif, display = "bp", choices = c(2),
                              scaling=2)), col = "red", cex = 1)
```
